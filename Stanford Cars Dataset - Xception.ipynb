{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standford Cars Vehicle Recognition - CNN modeling Xception ROUGH DRAFT\n",
    "\n",
    "### CODE ONLY, For a detailed report, please refer to the Final Report\n",
    "\n",
    "#### by Sean Sungil Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "#from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications import Xception\n",
    "import tensorflow as tf\n",
    "#import fastai\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# custom python scripts\n",
    "import SC_sungil             # preprocessing\n",
    "import ConvNet_sungil        # ConvNet modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for convenience, vehicle detected images are already saved\n",
    "# loading the pre-saved vehicle detected images, classes and labels\n",
    "train_detected_sc, train_data_class, data_labels = SC_sungil.load_images('saved_images/resized/training/',\\\n",
    "                                            'devkit/cars_train_annos.mat', None, 'devkit/cars_meta.mat')\n",
    "test_detected_sc, test_data_class = SC_sungil.load_images('saved_images/resized/testing/', None,\\\n",
    "                                                          'devkit/cars_test_annos_withlabels.mat', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combining the training and testing dataset\n",
    "all_data, all_class = SC_sungil.comb_data(train_detected_sc, test_detected_sc,\\\n",
    "                                          train_data_class, test_data_class)\n",
    "\n",
    "# removing year and mergining classes\n",
    "new_data_labels, all_class = SC_sungil.rmv_year(data_labels, all_class)\n",
    "all_class = all_class - 1\n",
    "\n",
    "# number of classes\n",
    "num_classes = len(new_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 80% train 20% test split\n",
    "# test_size was set to 0.1226, to maintain the validation set size to 20% post under-sampling\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_data, all_class, stratify = all_class,\\\n",
    "                                                    test_size = 0.1226)\n",
    "\n",
    "# random under-sampling\n",
    "und_x_train, und_y_train = SC_sungil.under_sample(x_train, y_train)\n",
    "\n",
    "# converting a class vector to binary class matrix\n",
    "y_train_bin = keras.utils.to_categorical(und_y_train, num_classes)\n",
    "y_test_bin = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# post split class distribution\n",
    "fig = plt.figure(figsize = (15, 5))\n",
    "plt.subplot(1, 3, 1), sns.distplot(all_class, bins = num_classes)\n",
    "plt.title('Distribution Plot of Classes in the Original Data', y = 1.02)\n",
    "plt.xlabel('Class Number'), plt.ylabel('Density')\n",
    "plt.subplot(1, 3, 2), sns.distplot(und_y_train, bins = num_classes)\n",
    "plt.title('Distribution Plot of Classes in the Re-split Training Set\\n(Under-sampled)', y = 1.02)\n",
    "plt.xlabel('Class Number'), plt.ylabel('Density')\n",
    "plt.subplot(1, 3, 3), sns.distplot(y_test, bins = num_classes)\n",
    "plt.title('Distribution Plot of Classes in the Re-split Testing Set', y = 1.02)\n",
    "plt.xlabel('Class Number'), plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "tot_len = len(und_x_train) + len(x_test)\n",
    "print('Total of %i images in the training data' % len(und_x_train))\n",
    "print('Total of %i images in the testing data' % len(x_test))\n",
    "print('%0.2f percent training set, %0.2f percent testing set' \\\n",
    "      % (len(und_x_train)/tot_len*100, len(x_test)/tot_len*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring with State-of-the-Art CNN Architectures\n",
    "\n",
    "#### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "train_datagen = ImageDataGenerator(rescale = 1. / 255, rotation_range = 40, width_shift_range = 0.2,\\\n",
    "                    height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True,\\\n",
    "                    fill_mode = 'nearest')\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "\n",
    "train_datagen.fit(und_x_train)\n",
    "test_datagen.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# base pre-trained InceptionV3 model\n",
    "#base_model = Xception(include_top = False, weights = 'imagenet', input_shape = und_x_train.shape[1:4])\n",
    "\n",
    "# global spatial average pooling, flattening, fully-connected, dropout and logistic layer\n",
    "#x = base_model.output\n",
    "#x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "#x = keras.layers.Dense(2048, activation = 'relu')(x)\n",
    "#x = keras.layers.Dropout(0.4)(x)\n",
    "#predictions = keras.layers.Dense(num_classes, activation = 'softmax')(x)\n",
    "\n",
    "# model1\n",
    "#model1 = Model(inputs = base_model.input, outputs = predictions)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# freezing all convolutional InceptionV3 layers to train only the top layers which were randomly initialized\n",
    "#for layer in base_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# compiling the model post freezing\n",
    "#model1.compile(optimizer = keras.optimizers.Adam(lr = 0.0001), loss = 'categorical_crossentropy',\\\n",
    "#               metrics = ['accuracy'])\n",
    "\n",
    "# learning rate finder\n",
    "#start_ts = time.time()\n",
    "#lr_finder1 = ConvNet_sungil.lr_finder(model1)\n",
    "#lr_finder1.find_generator(train_datagen.flow(und_x_train, y_train_bin, batch_size = 256),\\\n",
    "#                          start_lr = 0.00001, end_lr = 0.1, epochs = 2, steps_per_epoch = len(und_x_train) / 256)\n",
    "#print(\"Total Runtime:\", time.time() - start_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr_finder1.plot_loss(n_skip_beginning = 1)\n",
    "#lr_finder1.plot_loss_change(n_skip_beginning = 1, sma = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# setting the optimied learning rate\n",
    "#K.set_value(model1.optimizer.lr, 0.0001)\n",
    "\n",
    "# model checkpoint\n",
    "#mc = keras.callbacks.ModelCheckpoint('best_model1.h5', monitor = 'val_acc', mode = 'max',\\\n",
    "#                                     verbose = 1, save_best_only = True)\n",
    "\n",
    "# fitting the model on batches with real-time data augmentation\n",
    "# training the model (top layers) on the new data for 10 epochs\n",
    "#start_ts = time.time()\n",
    "#history1 = model1.fit_generator(train_datagen.flow(und_x_train, y_train_bin, batch_size = 256),\n",
    "#    steps_per_epoch = len(und_x_train) / 256, epochs = 10, callbacks = [mc],\\\n",
    "#    validation_data = test_datagen.flow(x_test, y_test_bin), validation_steps = len(x_test) / 256)\n",
    "#print(\"Total Runtime:\", time.time() - start_ts)\n",
    "\n",
    "# saving the model\n",
    "#model1.save('Xception_phase1-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy vs. epoch and loss vs. epoch graphs\n",
    "#plt.figure(figsize = (10, 5))\n",
    "#plt.subplot(1, 2, 1)\n",
    "#plt.plot(history1.history['acc']), plt.plot(history1.history['val_acc'])\n",
    "#plt.title('Model Accuracy'), plt.ylabel('Accuracy'), plt.xlabel('Epoch')\n",
    "#plt.legend(['train', 'test'], loc = 'upper left')\n",
    "#plt.subplot(1, 2, 2)\n",
    "#plt.plot(history1.history['loss']), plt.plot(history1.history['val_loss'])\n",
    "#plt.title('Model Loss'), plt.ylabel('Loss'), plt.xlabel('Epoch')\n",
    "#plt.legend(['train', 'test'], loc = 'upper left')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning convolutional layers \n",
    "# from inception V3. We will freeze the bottom N layers and train the remaining top layers.\n",
    "# let's visualize layer names and layer indices to see how many layers we should freeze:\n",
    "#for i, layer in enumerate(model1.layers):\n",
    "#    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading the model\n",
    "model1 = keras.models.load_model('Xception_phase1-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze the first 249 layers and unfreeze the rest:\n",
    "for layer in model1.layers[:115]:\n",
    "    print(layer.trainable)# = False\n",
    "for layer in model1.layers[115:]:\n",
    "    print(layer.trainable)# = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning rate finder\n",
    "#lr_finder1_1 = ConvNet_sungil.lr_finder(model1)\n",
    "#lr_finder1_1.find_generator(train_datagen.flow(und_x_train, y_train_bin, batch_size = 256),\\\n",
    "#                          start_lr = 0.00001, end_lr = 0.1, epochs = 2, steps_per_epoch = len(und_x_train) / 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr_finder1_1.plot_loss(n_skip_beginning = 1)\n",
    "#lr_finder1_1.plot_loss_change(n_skip_beginning = 1, sma = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finetuning and recompiling the model for unfreezing to take effect\n",
    "#model1.compile(optimizer = keras.optimizers.Adam(lr = 2*(10**(-5))), loss = 'categorical_crossentropy',\\\n",
    "#               metrics = ['accuracy'])\n",
    "\n",
    "# patient early stopping and model checkpoint\n",
    "es = keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)\n",
    "mc = keras.callbacks.ModelCheckpoint('Xception_phase1-2.h5', monitor = 'val_acc', mode = 'max',\\\n",
    "                                     verbose = 1, save_best_only = True)\n",
    "\n",
    "# model fitting\n",
    "start_ts = time.time()\n",
    "history1_1 = model1.fit_generator(train_datagen.flow(und_x_train, y_train_bin, batch_size = 256),\\\n",
    "                epochs = 10, steps_per_epoch = len(und_x_train) / 256, callbacks = [es, mc],\\\n",
    "                validation_data = test_datagen.flow(x_test, y_test_bin),\\\n",
    "                validation_steps = len(x_test) / 256)\n",
    "print(\"Total Runtime:\", time.time()-start_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy vs. epoch and loss vs. epoch graphs\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history1_1.history['acc']), plt.plot(history1_1.history['val_acc'])\n",
    "plt.title('Model Accuracy'), plt.ylabel('Accuracy'), plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history1_1.history['loss']), plt.plot(history1_1.history['val_loss'])\n",
    "plt.title('Model Loss'), plt.ylabel('Loss'), plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the model\n",
    "model1.save('Xception_phase1-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
